---
layout: post
categories: Fundamental
title: 关于贝叶斯
author: datasnail
comments: true
show: index
tags:
- markov
- 基础知识
---

#### **朴素贝叶斯分类器、半朴素贝叶斯分类器、贝叶斯网络 <sup>[1]</sup>**
**注：以下均来源于周老师的机器学习西瓜书，详细内容见第七章：贝叶斯分类器**

#### 1、朴素贝叶斯分类器
**朴素贝叶斯分类器**：贝叶斯公式$$P(c \mid x) = \frac {P(c) P(x \mid c) } {P(x) } $$来估计后验概率 $$P(c \mid x)$$的主要困难在于：类条件概率$$P(x \mid c)$$的所有属性上的联合概率，难以从有限的训练样本中估计而得。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”（attribute conditional independence assumption）：对已知类别，假设所有的属性相互独立。换言之，假设每个属性独立的对分类结果发生影响。<sup>[1]</sup>

基于此假设，贝叶斯公式可重写为：

$$P(c \mid x) = \frac {P(c) P(x \mid c) } {P(x) } = \frac {P(c)} {P(x) } \prod_{i=1}^d P(x_i \mid c)$$

可利用**拉普拉斯修正**，避免因训练集样本不充分而导致概率估值为零的问题。

#### 2、半朴素贝叶斯分类器

**半朴素贝叶斯分类器** :朴素贝叶斯采用的属性条件独立性假设，在现实中很往往很难成立。于是，人们尝试对属性条件独立性假设进行一定程度的放松，产生了“半朴素贝叶斯分类器”。适当考虑一部分属性间的相互依赖信息，从而既不需要进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。“独依赖估计”（One-Dependent Estimator,简称ODE)是半朴素贝叶斯分类器最常用的一种策略。“独依赖”是假设每个属性在类别之外最多仅依赖于一个其他属性,即：

$$P(c \mid x) 正比  P(c) \prod_{i=1}^d P(x_i \mid c, p a_i)$$

NB：

SPODE：设置超父节点。

TAN：通过在最大带权生成树的基础上，通过条件互信息建立依赖关系。

AODE（Averaged One-Dependent Estimator）[webb et al.,2015]:一种基于集成学习机制，更为强大的独立依赖分类器。与SPODE通过模型选择确定超父属性不同，AODE尝试将每个属性作为超父来构建SPODE，然后将那些具有足够训练数据支撑的SPODE集成起来作为最终结果。

#### 3、贝叶斯网

**贝叶斯网**：也称为“信念网”（belief network），借助于无环图DAG，来刻画属性之间的依赖关系。用条件概率表（CPT）来描述属性之间的联合概率分布。

**结构**：tail-to-tail 、 head-to-head 、 head-to-tail

**学习**：情况一、如果网络结构已知，则贝叶斯网络的学习过程相对简单，只需要通过对训练样本“计数”，估计出每个节点的条件概率表即可。
情况二、不知道网络结构，则贝叶斯网络的学习首要任务就是根据训练的数据集找出结构最“恰当”的贝叶斯网。“评分搜索”是求解这一问题的常用方法。

**推断**：最理想的是直接根据贝叶斯网定义的联合概率分布来精确地计算后验概率。不幸的是，“精确推断”被证明是NP-难。当网络节点较多，连接稠密时，难以进行精确推断，此时借助“近似推断”通过降低精度要求，在有限的实践内求得近似解。通常使用吉布斯采样来完成。

吉布斯采样如何工作：


[1]. 周志华，机器学习
[2].
